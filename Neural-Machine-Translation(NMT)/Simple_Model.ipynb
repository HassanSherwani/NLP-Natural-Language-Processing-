{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJxJLfT6m4zo"
   },
   "source": [
    "# Machine Translation\n",
    "\n",
    "English-German using basic language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YvFSu3KOnCQI"
   },
   "source": [
    "# 1)- Importing key modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydSdCo4JzRta"
   },
   "outputs": [],
   "source": [
    "#support both Python 2 and Python 3 with minimal overhead.\n",
    "from __future__ import absolute_import, division, print_function\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body {\n",
       "    margin: 0;\n",
       "    font-family: Helvetica;\n",
       "}\n",
       "table.dataframe {\n",
       "    border-collapse: collapse;\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe tr {\n",
       "    border: none;\n",
       "}\n",
       "table.dataframe td, table.dataframe th {\n",
       "    margin: 0;\n",
       "    border: 1px solid white;\n",
       "    padding-left: 0.25em;\n",
       "    padding-right: 0.25em;\n",
       "}\n",
       "table.dataframe th:not(:empty) {\n",
       "    background-color: #fec;\n",
       "    text-align: left;\n",
       "    font-weight: normal;\n",
       "}\n",
       "table.dataframe tr:nth-child(2) th:empty {\n",
       "    border-left: none;\n",
       "    border-right: 1px dashed #888;\n",
       "}\n",
       "table.dataframe td {\n",
       "    border: 2px solid #ccf;\n",
       "    background-color: #f4f4ff;\n",
       "}\n",
       "h3 {\n",
       "    color: white;\n",
       "    background-color: black;\n",
       "    padding: 0.5em;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's life without style :). So, let's add style to our dataframes\n",
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HXdjBXc-zNXe"
   },
   "outputs": [],
   "source": [
    "import string \n",
    "import re \n",
    "from numpy import array, argmax, random, take \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ElRcz5K3hJrC",
    "outputId": "e8d7eda4-83db-495e-f962-d98daf88909b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model \n",
    "from keras import optimizers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "IthtzOIHUtmR",
    "outputId": "b9fbbdba-fbd6-47a4-bdef-9cbf7be84972"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting version_information\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/b0/6088e15b9ac43a08ccd300d68e0b900a20cf62077596c11ad11dd8cc9e4b/version_information-1.0.3.tar.gz\n",
      "Building wheels for collected packages: version-information\n",
      "  Building wheel for version-information (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for version-information: filename=version_information-1.0.3-cp36-none-any.whl size=3880 sha256=9e46becc140b401733476faab2c42fe360e415267ee79a08c1c833c2d7bf0054\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/4c/b3/1976ac11dbd802723b564de1acaa453a72c36c95827e576321\n",
      "Successfully built version-information\n",
      "Installing collected packages: version-information\n",
      "Successfully installed version-information-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!  pip install version_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "83ZfAQ_OUwWv",
    "outputId": "7e138c26-b855-449d-a617-2f194edcf7b3"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]"
        },
        {
         "module": "IPython",
         "version": "5.5.0"
        },
        {
         "module": "OS",
         "version": "Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic"
        },
        {
         "module": "pandas",
         "version": "0.24.2"
        },
        {
         "module": "re",
         "version": "2.2.1"
        },
        {
         "module": "string",
         "version": "The 'string' distribution was not found and is required by the application"
        },
        {
         "module": "matplotlib",
         "version": "3.0.3"
        },
        {
         "module": "keras",
         "version": "2.2.5"
        },
        {
         "module": "tensorflow",
         "version": "1.14.0"
        },
        {
         "module": "numpy",
         "version": "1.16.5"
        },
        {
         "module": "sklearn",
         "version": "0.21.3"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]</td></tr><tr><td>IPython</td><td>5.5.0</td></tr><tr><td>OS</td><td>Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic</td></tr><tr><td>pandas</td><td>0.24.2</td></tr><tr><td>re</td><td>2.2.1</td></tr><tr><td>string</td><td>The 'string' distribution was not found and is required by the application</td></tr><tr><td>matplotlib</td><td>3.0.3</td></tr><tr><td>keras</td><td>2.2.5</td></tr><tr><td>tensorflow</td><td>1.14.0</td></tr><tr><td>numpy</td><td>1.16.5</td></tr><tr><td>sklearn</td><td>0.21.3</td></tr><tr><td colspan='2'>Mon Sep 16 13:46:25 2019 UTC</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383] \\\\ \\hline\n",
       "IPython & 5.5.0 \\\\ \\hline\n",
       "OS & Linux 4.14.137+ x86\\_64 with Ubuntu 18.04 bionic \\\\ \\hline\n",
       "pandas & 0.24.2 \\\\ \\hline\n",
       "re & 2.2.1 \\\\ \\hline\n",
       "string & The 'string' distribution was not found and is required by the application \\\\ \\hline\n",
       "matplotlib & 3.0.3 \\\\ \\hline\n",
       "keras & 2.2.5 \\\\ \\hline\n",
       "tensorflow & 1.14.0 \\\\ \\hline\n",
       "numpy & 1.16.5 \\\\ \\hline\n",
       "sklearn & 0.21.3 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Mon Sep 16 13:46:25 2019 UTC} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]\n",
       "IPython 5.5.0\n",
       "OS Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic\n",
       "pandas 0.24.2\n",
       "re 2.2.1\n",
       "string The 'string' distribution was not found and is required by the application\n",
       "matplotlib 3.0.3\n",
       "keras 2.2.5\n",
       "tensorflow 1.14.0\n",
       "numpy 1.16.5\n",
       "sklearn 0.21.3\n",
       "Mon Sep 16 13:46:25 2019 UTC"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext version_information\n",
    "%version_information pandas,re,string, matplotlib,keras,tensorflow,numpy,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XN_b91atnHye"
   },
   "source": [
    "# 2)- Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ffc2bMb7xJU"
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename): \n",
    "        # open the file \n",
    "        file = open(filename, mode='rt', encoding='utf-8') \n",
    "        \n",
    "        # read all text \n",
    "        text = file.read() \n",
    "        file.close() \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6ucxbaz7xMm"
   },
   "outputs": [],
   "source": [
    "# split text into sentences \n",
    "def to_lines(text): \n",
    "      sents = text.strip().split('\\n') \n",
    "      sents = [i.split('\\t') for i in sents] \n",
    "      return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P23QEeky7xPt"
   },
   "outputs": [],
   "source": [
    "data = read_text(\"random_data.txt\") \n",
    "deu_eng = to_lines(data) \n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5uE4Ka5gVYq-",
    "outputId": "e173e3eb-745f-465a-dfd1-932de26ebcef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(deu_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "5sQ0sxkw7xS3",
    "outputId": "ba2984f4-5b7d-4dd8-db91-2ce6c33a7b59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['india and japan prime ministers meet in tokyo',\n",
       "       'indias new prime minister narendra modi is meeting his japanese counterpart shinzo abe in tokyo to discuss economic and security ties on his first major foreign visit since winning mays election',\n",
       "       'mr modi is on a fiveday trip to japan to strengthen economic ties with the third largest economy in the world',\n",
       "       ..., 'five minutes later the first mountainbikers set off',\n",
       "       'bent hansen chairman of the association cycling on the grosser feldberg gave the starting orders and wished those taking part an enjoyable trip',\n",
       "       'next year he hopes to have safety barriers on the course for the benefit of those taking part on the feldberg'],\n",
       "      dtype='<U511')"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for english part \n",
    "deu_eng[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "QMxTVt657xV9",
    "outputId": "6a2b5687-b293-4b1a-8091-9a124f21ef98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['die premierminister indiens und japans trafen sich in tokio',\n",
       "       'indiens neuer premierminister narendra modi trifft bei seinem ersten wichtigen auslandsbesuch seit seinem wahlsieg im mai seinen japanischen amtskollegen shinzo abe in toko um wirtschaftliche und sicherheitspolitische beziehungen zu besprechen',\n",
       "       'herr modi befindet sich auf einer funftagigen reise nach japan um die wirtschaftlichen beziehungen mit der drittgroten wirtschaftsnation der welt zu festigen',\n",
       "       ..., 'funf minuten spater legten die ersten mountainbiker los',\n",
       "       'bent hansen vorsitzender des vereins radeln auf den groen feldberg gab die startkommandos und wunschte den teilnehmern einen schonen ausflug',\n",
       "       'fur nachstes jahr hoffe er dass es gelingt die strecke zum feldberg hinauf zur sicherheit der teilnehmer zu sperren'],\n",
       "      dtype='<U511')"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for german version of data\n",
    "deu_eng[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUZ6BSmvtJ1s"
   },
   "source": [
    "# 3)-Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GEia-m7ViPLD"
   },
   "source": [
    "### 3.1)-Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WmC81k-wh8ZJ"
   },
   "outputs": [],
   "source": [
    "# Remove punctuation \n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]] \n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]] \n",
    "\n",
    "# convert text to lowercase \n",
    "for i in range(len(deu_eng)): \n",
    "    deu_eng[i,0] = deu_eng[i,0].lower() \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4FdyDdXwiS9i"
   },
   "source": [
    "### 3.2)-Text to Sequence Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "colab_type": "code",
    "id": "8pxu1-xNh8cA",
    "outputId": "82c20837-8df2-4ad5-8a48-2a264cf155fc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty lists \n",
    "eng_l = [] \n",
    "deu_l = [] \n",
    "\n",
    "# populate the lists with sentence lengths \n",
    "for i in deu_eng[:,0]: \n",
    "      eng_l.append(len(i.split())) \n",
    "\n",
    "for i in deu_eng[:,1]: \n",
    "      deu_l.append(len(i.split())) \n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
    "length_df.hist(bins = 30) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2De4ZERJzX_4"
   },
   "source": [
    "the maximum length of the German sentences(target) is 73 where  max. lenth of English(input seq) is 71. But, their distribution pattern is different from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lpt6tCjfkGKu"
   },
   "source": [
    "### 3.3)-vectorize our text data \n",
    "\n",
    "by using Kerasâ€™s Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_j_y_uZ7h8e6",
    "outputId": "efac6714-dfc7-4d5b-d617-c08de4f994ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 7231\n"
     ]
    }
   ],
   "source": [
    "# function to build a tokenizer \n",
    "def tokenization(lines): \n",
    "      tokenizer = Tokenizer() \n",
    "      tokenizer.fit_on_texts(lines) \n",
    "      return tokenizer\n",
    "\n",
    "# prepare english tokenizer \n",
    "eng_tokenizer = tokenization(deu_eng[:, 0]) \n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1 \n",
    "eng_length = 71  \n",
    "\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0ha_ZNySh8hh",
    "outputId": "f410817d-9500-469b-d551-b18f47fe71bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 9284\n"
     ]
    }
   ],
   "source": [
    "# prepare Deutch tokenizer \n",
    "deu_tokenizer = tokenization(deu_eng[:, 1]) \n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1 \n",
    "deu_length = 71 # keeping aligned with input sequence\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvmowmplzfdT"
   },
   "source": [
    "There is difference in amount of words in two languages.We need to encode sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cUY-Py6WzhtB"
   },
   "source": [
    "### 3.4)-encode and pad sequences \n",
    "\n",
    " pad those sequences with zeros to make all the sequences of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QElAizsykOtJ"
   },
   "outputs": [],
   "source": [
    "def encode_sequences(tokenizer, length, lines):          \n",
    "         # integer encode sequences          \n",
    "         seq = tokenizer.texts_to_sequences(lines)          \n",
    "         # pad sequences with 0 values          \n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')           \n",
    "         return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "408A3w7Ukb4r"
   },
   "source": [
    "# 4)-Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJF5iWUOnUgC"
   },
   "source": [
    "### 4.1)- Train-test Split\n",
    "\n",
    "80%-20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzxozTM0kZk7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# split data into train and test set \n",
    "train,test= train_test_split(deu_eng,test_size=0.2,random_state= 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xvyO7SdQkr88"
   },
   "source": [
    "### 4.2)- Defining input and target\n",
    "We will encode English sentences as the input sequences and German sentences as the target sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "wJvJMU9Vzr-7",
    "outputId": "fe2b51be-9468-4099-853a-d55216f5516d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['its not my responsibility',\n",
       "       'meanwhile in our homes items as innocuous as floor tiles or shed roofs have routinely contained asbestos',\n",
       "       'she said i keep thinking this world did not get better within these years',\n",
       "       ...,\n",
       "       'crops are rotting in the fields mines have been deserted and the markets have been abandoned the virus has cost the region dearly',\n",
       "       'the preparations for the party are well underway in tannenwald gun club which will celebrate years since being established on to september',\n",
       "       'it also means higher taxes'], dtype='<U511')"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# english version\n",
    "train[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "TcMT6wFoztLT",
    "outputId": "2ffc14d1-b0d5-4e62-88c2-68aed01074f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ich bin nicht dafur verantwortlich',\n",
       "       'und derweil haben so unschuldige gegenstande in unseren hausern wie fubodenplatten oder schuppendacher standardmaig asbest enthalten',\n",
       "       'sie sagte ich denke immer dass diese welt in diesen jahren nicht besser geworden ist',\n",
       "       ...,\n",
       "       'die ernte verrottet auf den feldern die minen sind verlassen und die markte verwaist das virus hat der region schwer zugesetzt',\n",
       "       'auf hochtouren laufen beim schutzenverein tannenwald die vorbereitungen fur das grundungsfest von bis september',\n",
       "       'sie bedeutet auch hohere steuern'], dtype='<U511')"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# english version\n",
    "train[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bGH5NgnAVsEm"
   },
   "source": [
    "**apply sequence encoding on both train and validation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P6ZhWiJdkkb8"
   },
   "outputs": [],
   "source": [
    "# prepare training data \n",
    "trainX = encode_sequences(eng_tokenizer, deu_length, train[:, 0]) \n",
    "trainY = encode_sequences(deu_tokenizer, eng_length, train[:, 1]) \n",
    "\n",
    "# prepare validation data \n",
    "testX = encode_sequences(eng_tokenizer, deu_length, test[:, 0]) \n",
    "testY = encode_sequences(deu_tokenizer, eng_length, test[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "f2LKJrFfz0GI",
    "outputId": "d8447d94-6593-4246-e5c1-c85b76e228cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  48   23   51 4075    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 567    4   86  439 5283   14 2913   14 2903 2904   64 2016 5284   17\n",
      "  5285 2943   65    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [  46   26   13 1113  648   30  141   97   23   98  179  362  193   58\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 518  136    3    1 1521 1147    4  148  211    9    1 1522  465   15\n",
      "   183    5 1368  623  407  444   17 2529    2 1693  121    1  501  188\n",
      "    69  610  427   23 1523 1892 2202 5445    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 188  697    5  475  873 1617  926  204    2  120    5  130 6116    4\n",
      "  2786   29 1329    3  113   76    1  204 3174    4    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "print(trainX[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "L81CkA-Rz0Jh",
    "outputId": "0d514dcd-676f-4061-845d-5aef20af7af5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  15  184   18  272 1521    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   3 1037   49   43 6213 6214    4  753 1071   30 2751   59 6215 6216\n",
      "    85 1223    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [  13   38   15  494   87   10   62  197    4  261  100   18  323  708\n",
      "    16    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 528    2 6471 1747    4  185  207    1 1234 2833 6472 6473 6474 1021\n",
      "  6475  209  957  189 6476   49    5 6477 6478   55 1233  208 6479 6480\n",
      "   956 1466    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 117   17  382  647  394    3  359 3054  401  180   25  646    3  453\n",
      "   741   17 7569   12  257   31   65  264    5  550    6    4  592    6\n",
      "   180    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "plUoF_-gz0Mh",
    "outputId": "462a24e9-ad9e-48a6-8bf0-33f1abda8a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5205, 71)\n",
      "(5205, 71)\n",
      "(1302, 71)\n",
      "(1302, 71)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)\n",
    "print(testX.shape)\n",
    "print(testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ubte9AUngfx"
   },
   "source": [
    "### 4.3)- build NMT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yORpCfMCkkjz"
   },
   "outputs": [],
   "source": [
    " def build_model(in_vocab,out_vocab, in_timesteps,out_timesteps,n):   \n",
    "      model = Sequential() \n",
    "      model.add(Embedding(in_vocab, n, input_length=in_timesteps,   \n",
    "      mask_zero=True)) \n",
    "      model.add(LSTM(n)) \n",
    "      model.add(RepeatVector(out_timesteps)) \n",
    "      model.add(LSTM(n, return_sequences=True))  \n",
    "      model.add(Dense(out_vocab, activation='softmax')) \n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "H_0LMdC6lgnp",
    "outputId": "9df17f4b-e90b-4b22-9571-e2bec035adac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3239: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3622: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model compilation (with 512 hidden units)\n",
    "model = build_model(eng_vocab_size,deu_vocab_size, eng_length, deu_length, 512)\n",
    "\n",
    "rms = optimizers.RMSprop(lr=0.001) \n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "BA8KW2_80Hs3",
    "outputId": "d9dfb193-804b-4605-e8ac-352a9042697b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 71, 512)           3702272   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 71, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 71, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 71, 9284)          4762692   \n",
      "=================================================================\n",
      "Total params: 12,663,364\n",
      "Trainable params: 12,663,364\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9M1ukVFAlkFz",
    "outputId": "08bb5842-fae9-4a05-b820-c613fc86e750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 4164 samples, validate on 1041 samples\n",
      "Epoch 1/30\n",
      "4164/4164 [==============================] - 26s 6ms/step - loss: 4.6830 - val_loss: 2.3161\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.31610, saving model to model_translate.h1\n",
      "Epoch 2/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.2885 - val_loss: 2.2566\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.31610 to 2.25660, saving model to model_translate.h1\n",
      "Epoch 3/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.2988 - val_loss: 2.2530\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.25660 to 2.25296, saving model to model_translate.h1\n",
      "Epoch 4/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.3147 - val_loss: 2.2030\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.25296 to 2.20297, saving model to model_translate.h1\n",
      "Epoch 5/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.2080 - val_loss: 2.0795\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.20297 to 2.07954, saving model to model_translate.h1\n",
      "Epoch 6/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.3137 - val_loss: 2.1292\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.07954\n",
      "Epoch 7/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.1681 - val_loss: 2.0662\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.07954 to 2.06621, saving model to model_translate.h1\n",
      "Epoch 8/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.1317 - val_loss: 2.1192\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.06621\n",
      "Epoch 9/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.1145 - val_loss: 2.1491\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.06621\n",
      "Epoch 10/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.0622 - val_loss: 2.4042\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.06621\n",
      "Epoch 11/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.0922 - val_loss: 1.9219\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.06621 to 1.92186, saving model to model_translate.h1\n",
      "Epoch 12/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 2.0692 - val_loss: 1.9949\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.92186\n",
      "Epoch 13/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.9621 - val_loss: 1.9065\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.92186 to 1.90654, saving model to model_translate.h1\n",
      "Epoch 14/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.9309 - val_loss: 2.0216\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.90654\n",
      "Epoch 15/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.8886 - val_loss: 2.3658\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.90654\n",
      "Epoch 16/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.9364 - val_loss: 1.9532\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.90654\n",
      "Epoch 17/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.8730 - val_loss: 1.8841\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.90654 to 1.88410, saving model to model_translate.h1\n",
      "Epoch 18/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.8855 - val_loss: 1.8732\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.88410 to 1.87319, saving model to model_translate.h1\n",
      "Epoch 19/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.8336 - val_loss: 1.8384\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.87319 to 1.83841, saving model to model_translate.h1\n",
      "Epoch 20/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.8557 - val_loss: 1.8649\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 1.83841\n",
      "Epoch 21/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.8029 - val_loss: 1.8920\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.83841\n",
      "Epoch 22/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.8018 - val_loss: 1.8344\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.83841 to 1.83442, saving model to model_translate.h1\n",
      "Epoch 23/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.7823 - val_loss: 1.8047\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.83442 to 1.80467, saving model to model_translate.h1\n",
      "Epoch 24/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.7933 - val_loss: 1.7956\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.80467 to 1.79562, saving model to model_translate.h1\n",
      "Epoch 25/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.7725 - val_loss: 1.7913\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.79562 to 1.79131, saving model to model_translate.h1\n",
      "Epoch 26/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.7386 - val_loss: 1.7866\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.79131 to 1.78659, saving model to model_translate.h1\n",
      "Epoch 27/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.7392 - val_loss: 1.8004\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.78659\n",
      "Epoch 28/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.7256 - val_loss: 1.7655\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.78659 to 1.76555, saving model to model_translate.h1\n",
      "Epoch 29/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.7290 - val_loss: 1.7608\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.76555 to 1.76083, saving model to model_translate.h1\n",
      "Epoch 30/30\n",
      "4164/4164 [==============================] - 20s 5ms/step - loss: 1.6957 - val_loss: 1.7574\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.76083 to 1.75736, saving model to model_translate.h1\n"
     ]
    }
   ],
   "source": [
    "filename = 'model_translate.h1' \n",
    "\n",
    "# set checkpoint\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss',  \n",
    "                             verbose=1, save_best_only=True, \n",
    "                             mode='min') \n",
    "\n",
    "\n",
    "# train model \n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "                    epochs=30, batch_size=512, validation_split = 0.2, \n",
    "                    callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nwrL0_sjmUuO"
   },
   "source": [
    "# 5)-Plotting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "iUYdtjQXlupF",
    "outputId": "46b98ffd-9cd6-4845-fe53-83b2cc69d35c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQlVJJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.legend(['train','validation']) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xQVCiaNDn4VJ"
   },
   "source": [
    "As you can see in the above plot, the validation loss kept on improving and is aligned with training sample.Hence, there is no over-fitting.\n",
    "\n",
    "We have got a reasonable outcome with 30 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FgePSmZBmSbn"
   },
   "source": [
    "# 6)-Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6gh_CukCl7Al"
   },
   "outputs": [],
   "source": [
    "model = load_model('model_translate.h1') \n",
    "\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0], testX.shape[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-DaR0x4oA4P"
   },
   "source": [
    "These predictions are sequences of integers. We need to convert these integers to their corresponding words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VU6IOmOOoB3f"
   },
   "source": [
    "### 6.1)- Convert integers to words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oiy9gGAAmAat"
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):  \n",
    "      for word, index in tokenizer.word_index.items():                       \n",
    "          if index == n: \n",
    "              return word \n",
    "      return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KqSwZTcXmDTW"
   },
   "source": [
    "### 6.2)-Convert predictions into text (German)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y82jlYQMmAg0"
   },
   "outputs": [],
   "source": [
    "preds_text = [] \n",
    "for i in preds:        \n",
    "       temp = []        \n",
    "       for j in range(len(i)):             \n",
    "            t = get_word(i[j], deu_tokenizer)             \n",
    "            if j > 0:                 \n",
    "                if (t==get_word(i[j-1],deu_tokenizer))or(t== None):                       \n",
    "                     temp.append('')                 \n",
    "                else:                      \n",
    "                     temp.append(t)             \n",
    "            else:                    \n",
    "                if(t == None):                                   \n",
    "                     temp.append('')                    \n",
    "                else:                           \n",
    "                     temp.append(t)        \n",
    "       preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOAI5cB8mAj3"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,1], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "S2orsrv6oo4o",
    "outputId": "839ffbe6-326c-4873-b228-b471ed89b7a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wahrend die konkurrenz naher ruckt und neue technologien alte bequeme sicherheiten bedrohen ist die anstehende verhandlung der lizenzgebuhren fur die bbc mit besonderen gefahren verbunden</td>\n",
       "      <td>die       und    der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>luther rabinowitz lie seine pyramide zusammenfallen</td>\n",
       "      <td>ich ist  nicht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kurzlich erklarten die gesundheitsbehorden die krankheit sei in jeden winkel des landes vorgedrungen</td>\n",
       "      <td>die     und   in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ich billige den tweet nicht und habe ihn geloscht hie es in der spateren nachricht</td>\n",
       "      <td>die      und  der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fur den chef des oberurseler kultkiosks gehoren radtouren uber den feldberg einfach dazu</td>\n",
       "      <td>die      und  in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                        actual                                                                          predicted\n",
       "0  wahrend die konkurrenz naher ruckt und neue technologien alte bequeme sicherheiten bedrohen ist die anstehende verhandlung der lizenzgebuhren fur die bbc mit besonderen gefahren verbunden    die       und    der                                                           \n",
       "1                                                                                                                                          luther rabinowitz lie seine pyramide zusammenfallen  ich ist  nicht                                                                   \n",
       "2                                                                                         kurzlich erklarten die gesundheitsbehorden die krankheit sei in jeden winkel des landes vorgedrungen     die     und   in                                                              \n",
       "3                                                                                                           ich billige den tweet nicht und habe ihn geloscht hie es in der spateren nachricht    die      und  der                                                              \n",
       "4                                                                                                     fur den chef des oberurseler kultkiosks gehoren radtouren uber den feldberg einfach dazu     die      und  in                                                              "
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st 5 rows\n",
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "LPocsO00mJy-",
    "outputId": "ab3640a0-1ce7-4748-9cf1-987993a993e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>das ist auch an land ein guter rat aber er ist unter wasser umso wichtiger wegen der schlechten lichtverhaltnisse</td>\n",
       "      <td>die      und  der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>charity cmt uk teilte mit dass fehldiagnosen ein haufiges problem bei menschen mit cmt sind weil so wenig uber diese krankheit bekannt ist</td>\n",
       "      <td>die      und   der</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>dem ist erwartungsgema nicht so</td>\n",
       "      <td>ich ist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>es gab auf der ganzen welt nichts anderes zu sehen als ihr ungekammtes rabenschwarzes haar</td>\n",
       "      <td>die     und   in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>die demonstranten fordern den rucktritt des regierungschefs dem sie wahlbetrug vorwerfen</td>\n",
       "      <td>die     und  der</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                          actual                                                                        predicted\n",
       "461                            das ist auch an land ein guter rat aber er ist unter wasser umso wichtiger wegen der schlechten lichtverhaltnisse  die      und  der                                                              \n",
       "1213  charity cmt uk teilte mit dass fehldiagnosen ein haufiges problem bei menschen mit cmt sind weil so wenig uber diese krankheit bekannt ist  die      und   der                                                             \n",
       "191                                                                                                              dem ist erwartungsgema nicht so     ich ist                                                                     \n",
       "633                                                   es gab auf der ganzen welt nichts anderes zu sehen als ihr ungekammtes rabenschwarzes haar   die     und   in                                                              \n",
       "637                                                     die demonstranten fordern den rucktritt des regierungschefs dem sie wahlbetrug vorwerfen  die     und  der                                                               "
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print 5 rows randomly \n",
    "pred_df.sample(5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Simple_Model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
